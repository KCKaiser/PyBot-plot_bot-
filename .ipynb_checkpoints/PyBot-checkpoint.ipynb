{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from config import consumer_key, consumer_secret, access_token, access_token_secret\n",
    "\n",
    "except:\n",
    "    consumer_key = os.environ['CONSUMER_KEY']\n",
    "    consumer_secret = os.environ['CONSUMER_SECRET']\n",
    "    access_token = os.environ['ACCESS_TOKEN']\n",
    "    access_token_secret = os.environ['ACCESS_TOKEN_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createplot(sentiments_df, target_user):\n",
    "    style.use('ggplot')\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    x_vals = sentiments_df[\"Tweets Ago\"]\n",
    "    y_vals = sentiments_df[\"Compound\"]\n",
    "    sentiment_plt, = plt.plot(sentiments_df[\"Tweets Ago\"], sentiments_df[\"Compound\"], marker = \"o\", linewidth = 0.5, \n",
    "                          color = \"royalblue\", alpha = 0.8)\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%Y-%m-%d %H:%M\")\n",
    "    plt.title(f\"Sentiment Analysis of Tweets ({now}) for {target_user}\")\n",
    "    plt.xlim([x_vals.max(),x_vals.min()]) \n",
    "    plt.ylabel(\"Tweet Polarity\")\n",
    "    plt.xlabel(\"Tweets Ago\")\n",
    "    plt.xticks(size = 9)\n",
    "    plt.yticks(size = 9)\n",
    "    plt.xlim(min(sentiments_df[\"Tweets Ago\"]) - 2, 2) \n",
    "    lgd = plt.legend([sentiment_plt], [target_user], loc = \"right\", bbox_to_anchor=(1.31, 0.9))\n",
    "\n",
    "    plt.savefig(f'output_images/{target_user[1:]}.png', bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweetout(target_user, person_to_thank):\n",
    "    api.update_with_media(f'output_images/{target_user[1:]}.png',\n",
    "                          f'New Tweet Analysis: {target_user} (Thanks @{person_to_thank}!)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = []\n",
    "analysis_targets = []\n",
    "\n",
    "# Searching for mentions\n",
    "target_term = \"@plot_bot\"\n",
    "\n",
    "\n",
    "def plotbot():\n",
    "    \n",
    "    # Searching for mentions\n",
    "    public_tweets = api.search(target_term, count=100, result_type=\"recent\")\n",
    "    \n",
    "    # For every tweet from our search...\n",
    "    for tweet in public_tweets[\"statuses\"]:\n",
    "\n",
    "        tweet_id = tweet[\"id\"]\n",
    "        \n",
    "        # Find unique tweets that were not previously used\n",
    "        if tweet_id not in tweet_ids:\n",
    "            \n",
    "            # Append the tweet id for this tweet to a list\n",
    "            tweet_ids.append(tweet_id)\n",
    "            \n",
    "            # Pull out the name of the user who tweeted @plot_bot\n",
    "            person_to_thank = tweet[\"user\"][\"screen_name\"]\n",
    "            \n",
    "            # Pull out the username of the user we're analyzing from the tweet itself\n",
    "            tweet_text = tweet[\"text\"]\n",
    "            tweet_index = tweet_text.find(target_term)\n",
    "            tweet_space = tweet_text.find(\"@\", tweet_index + 1)\n",
    "            \n",
    "            \n",
    "            # Do so if only if the tweet has the word \"analyze\" and has a second username mention\n",
    "            if not tweet_text.find(\"Analyze\")== -1 or not tweet_text.find(\"analyze\")== -1:\n",
    "                if not tweet_space == -1:\n",
    "                    # Making sure the code still works regardless if there is space after the second username\n",
    "                    if not tweet_text[tweet_space: ].find(\" \")== -1:\n",
    "                        tweet_short = tweet_text[tweet_space:]\n",
    "                        index_space = tweet_text[tweet_space: ].find(\" \")\n",
    "                        target_user = tweet_short[:index_space]\n",
    "            \n",
    "                    else:\n",
    "                        target_user = tweet_text[tweet_space: ]\n",
    "            \n",
    "                    # For every tweet from our search that are unique and the target has not been analyzed before\n",
    "                    #(And the tweet uses the word analyze and mentions a second username)\n",
    "                    if target_user not in analysis_targets:\n",
    "                        analysis_targets.append(target_user)\n",
    "\n",
    "                        oldest_tweet = None\n",
    "                        sentiments = []\n",
    "                        twitter_ids = []\n",
    "                        counter = -1\n",
    "\n",
    "                        # For every tweet from our search that are unique and the target has not been analyzed before,\n",
    "                        # Flip through 25 pages for 500 tweets from the target\n",
    "                        for x in range(25):\n",
    "                            user_tweets = api.user_timeline(target_user, max_id = oldest_tweet)\n",
    "\n",
    "                            # For every page for the new target from every unique tweet from our search...\n",
    "                            for user_tweet in user_tweets:\n",
    "\n",
    "                                twitter_id = user_tweet[\"id\"]\n",
    "\n",
    "                                # Make sure we're not pulling duplicate tweets\n",
    "                                if twitter_id not in twitter_ids:\n",
    "\n",
    "                                    twitter_ids.append(twitter_id)\n",
    "\n",
    "                                    user_text = user_tweet[\"text\"]\n",
    "\n",
    "                                    results = analyzer.polarity_scores(user_text)\n",
    "\n",
    "                                    oldest_tweet = user_tweet['id'] - 1\n",
    "\n",
    "                                    sentiment_dictionary = {\"Date\": tweet[\"created_at\"],\n",
    "                                                            \"Compound\" : results[\"compound\"],\n",
    "                                                            \"Positive\" : results[\"pos\"],\n",
    "                                                            \"Negative\" : results[\"neg\"],\n",
    "                                                            \"Neutral\" : results[\"neu\"],\n",
    "                                                            \"Tweets Ago\" : counter}              \n",
    "\n",
    "                                    sentiments.append(sentiment_dictionary)\n",
    "                                    counter -= 1\n",
    "\n",
    "                                sentiments_df = pd.DataFrame(sentiments)\n",
    "\n",
    "                        createplot(sentiments_df, target_user)\n",
    "                        #tweetout(target_user, person_to_thank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    plotbot()\n",
    "    time.sleep(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
